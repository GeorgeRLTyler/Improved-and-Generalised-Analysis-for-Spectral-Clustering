{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports and Settings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcf027de43a9ee56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "\n",
    "# make text larger\n",
    "plt.rc('font', size=16)\n",
    "# set random seed\n",
    "np.random.seed(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating Graphs From Gaussians\n",
    "We create a plot of 4 gaussian clusters with 100 nodes each."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f15a202356192a60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_k_way_estimate(normalised_L, indicator_vectors, K):\n",
    "    k_way_possibilities = []\n",
    "    assert indicator_vectors.shape[1] == K, 'Indicator vectors should have K columns'\n",
    "    for i in range(K):\n",
    "        indicator = indicator_vectors[:, i]\n",
    "        val = indicator.T @ normalised_L @ indicator\n",
    "        k_way_possibilities.append(val)\n",
    "    return max(k_way_possibilities)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80a63f028cac4216"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "X1 = np.random.multivariate_normal(mean = [0,0], cov = [[1,0.5],[0.5,1]], size = 100)\n",
    "X2 = np.random.multivariate_normal(mean = [0,5], cov = [[1,-0.5],[-0.5,1]], size = 100)\n",
    "X3 = np.random.multivariate_normal(mean = [8,0], cov = [[1.5,0],[0,1]], size = 100)\n",
    "X4 = np.random.multivariate_normal(mean = [7,5], cov = [[1,0.2],[0.2,1]], size = 100)\n",
    "X = np.concatenate((X1, X2, X3, X4))\n",
    "# plot with each cluster in a different color\n",
    "plt.scatter(X1[:,0], X1[:,1], color = 'r')\n",
    "plt.scatter(X2[:,0], X2[:,1], color = 'b')\n",
    "plt.scatter(X3[:,0], X3[:,1], color = 'g')\n",
    "plt.scatter(X4[:,0], X4[:,1], color = 'y')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "#plt.title('4 Gaussian Clusters')\n",
    "plt.savefig('Figures/4GaussianClusters.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6572ac374d51b04b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# construct a graph from the data points using a threshold\n",
    "def construct_graph(X, threshold):\n",
    "    N = X.shape[0]\n",
    "    A = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dist = np.linalg.norm(X[i] - X[j])\n",
    "                if dist < threshold:\n",
    "                    A[i, j] = 1\n",
    "    return A\n",
    "\n",
    "A = construct_graph(X, 4)\n",
    "plt.figure()\n",
    "G = nx.from_numpy_array(A)\n",
    "pos = X\n",
    "# make edges thin and transparent. \n",
    "colormap = ['r'] * 100 + ['b'] * 100 + ['g'] * 100 + ['y'] * 100\n",
    "nx.draw(G, pos = pos, node_size = 10, edge_color = 'grey', width = 0.2, node_color = colormap)\n",
    "#plt.title('Graph Constructed from 4 Gaussian Clusters \\n Threshold = 4')\n",
    "plt.savefig('Figures/4GaussianClustersGraphThreshold4.png', bbox_inches = 'tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a126ecd8c88cc65b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute the normalized laplacian\n",
    "\n",
    "degrees = np.sum(A, axis = 1)\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "norm_L = np.eye(A.shape[0]) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "eigvals, eigvecs = np.linalg.eigh(norm_L)\n",
    "idx = np.argsort(eigvals)\n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "\n",
    "# plot first 10 eigenvalues\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "plt.grid(True)\n",
    "plt.scatter(range(1,9), eigvals[:8])\n",
    "plt.xlabel('Index')\n",
    "plt.xlim(1, 8.6)\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), minor=True)\n",
    "#plt.title(r\"First 8 Eigenvalues of $\\mathcal{L}$\")\n",
    "# write value on each point in small text\n",
    "for i in range(8):\n",
    "    plt.text(i + 1, eigvals[i], f'{eigvals[i]:.2f}', fontsize=10)\n",
    "plt.savefig('Figures/4GaussianClusters8Eigenvalues.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "217e1b33e50f549c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indicator_vectors = np.zeros((eigvecs.shape[0], 4))\n",
    "D_sqrt = np.diag(np.sqrt(degrees))\n",
    "for i in range(4):\n",
    "    indicator_vectors[100*i:100*(i+1), i] = 1\n",
    "    indicator_vectors[:, i] = D_sqrt @ indicator_vectors[:, i]\n",
    "    indicator_vectors[:, i] = indicator_vectors[:, i] / np.linalg.norm(indicator_vectors[:, i])\n",
    "\n",
    "# project indicator vectors onto the eigenvectors\n",
    "Q_K_by_K = (indicator_vectors.T @ eigvecs[:,:4])\n",
    "combined_indicator_vectors = indicator_vectors @ Q_K_by_K\n",
    "\n",
    "for i in range(4):\n",
    "    combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] / np.linalg.norm(combined_indicator_vectors[:, i])\n",
    "    for j in range(i):\n",
    "        combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] - (combined_indicator_vectors[:, j].T @ combined_indicator_vectors[:, i]) * combined_indicator_vectors[:, j]\n",
    "    combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] / np.linalg.norm(combined_indicator_vectors[:, i])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec864dff18c057b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rayleigh_quotients = np.diag(combined_indicator_vectors.T @ norm_L @ combined_indicator_vectors)\n",
    "# sort\n",
    "sorted_rayleigh_quotients = np.sort(rayleigh_quotients)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "187adc7bf057b284"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute true value\n",
    "true_val_matrix = eigvecs[:,:4] - combined_indicator_vectors @ (np.conj(combined_indicator_vectors).T @ eigvecs[:,:4])\n",
    "true_val = np.linalg.norm(true_val_matrix)**2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42a27b37f50d8156"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "B_1 = (rayleigh_quotients[0]+rayleigh_quotients[1])/(eigvals[2])\n",
    "B_2 = (rayleigh_quotients[2] + rayleigh_quotients[3] - 2*eigvals[2] + eigvals[4]*B_1)/(eigvals[4] - eigvals[2])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df4c664be9af83e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"True Value: \", true_val)\n",
    "print(f\"Upper Bound from Recursive Structure Theorem: {B_1 + B_2}\")\n",
    "print(f\"Lower Bound from General Structure Theorem: {np.sum(rayleigh_quotients)/eigvals[4]}\")\n",
    "print(f\"Lower Bound from Structure Theorem: {4*compute_k_way_estimate(norm_L, indicator_vectors, 4)/eigvals[4]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3d3b83f506e2e0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering of AISTATS Text Image\n",
    "In this section we construct a graph from the AISTATS text image and perform spectral clustering on the graph. We then compute and compare our bounds."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1ff13a9a5897b00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "im = cv2.imread('Data/AISTATS2025-TEXT.png')\n",
    "plt.imshow(im)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6563ea774820cf5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "im = cv2.imread('Data/AISTATS2025-TEXT.png')\n",
    "plt.imshow(im)\n",
    "smoothed_im = gaussian_filter(im, sigma=1)\n",
    "rescaled_smoothed_im = rescale(smoothed_im, 0.15, anti_aliasing=False)\n",
    "rescaled_smoothed_im = rescaled_smoothed_im[:, :, 0]\n",
    "plt.imshow(rescaled_smoothed_im[:,:])\n",
    "# remove axes\n",
    "plt.axis('off')\n",
    "plt.savefig(\"Figures/AISTATS2025-TEXT-GAUSSIANFILTER.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b9ceddc14b7d382"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute distance matrix\n",
    "euc_distances_color = euclidean_distances(rescaled_smoothed_im.reshape(-1, 1))\n",
    "euc_distances_color = euc_distances_color / euc_distances_color.max()\n",
    "euc_distances_color_squared = euc_distances_color ** 2\n",
    "\n",
    "euc_distances_distance = euclidean_distances(np.arange(rescaled_smoothed_im.size).reshape(-1, 1))\n",
    "euc_distances_distance = euc_distances_distance / euc_distances_distance.max()\n",
    "euc_distances_distance_squared = euc_distances_distance ** 2\n",
    "\n",
    "\n",
    "def sigma_median(distances: np.ndarray) -> float:\n",
    "    triu_distances = np.triu(distances, k=1)\n",
    "    # choose not to include 0 distances in the calculation\n",
    "    sigma = np.median(triu_distances[triu_distances > 0])\n",
    "    return sigma\n",
    "\n",
    "\n",
    "sigma_color = sigma_median(euc_distances_color)\n",
    "sigma_distance = sigma_median(euc_distances_distance)\n",
    "affinity_matrix = np.exp(-euc_distances_color_squared / (2 * sigma_color ** 2)) * np.exp(\n",
    "    -euc_distances_distance_squared / (2 * sigma_distance ** 2))\n",
    "# set diagonal to 0\n",
    "np.fill_diagonal(affinity_matrix, 0)\n",
    "# construct norm laplacian\n",
    "degrees = np.sum(affinity_matrix, axis=1)\n",
    "normalized_laplacian = np.eye(affinity_matrix.shape[0]) - np.diag(\n",
    "    1 / np.sqrt(np.sum(affinity_matrix, axis=1))) @ affinity_matrix @ np.diag(\n",
    "    1 / np.sqrt(np.sum(affinity_matrix, axis=1)))\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(normalized_laplacian)\n",
    "idx = eigenvalues.argsort()\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c2c5355f02c18d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# apply spectral clustering\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "labels = kmeans.fit_predict(eigenvectors[:, 0:n_clusters])\n",
    "\n",
    "# Reshape the labels to the image shape\n",
    "segmented_image = labels.reshape(rescaled_smoothed_im.shape)\n",
    "plt.imshow(segmented_image)\n",
    "plt.axis('off')\n",
    "plt.savefig('Figures/AISTATS2025-TEXT-3CLUSTERS.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d5e1223dedf0008"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute indicator vectors\n",
    "indicator_vectors = np.zeros((eigenvectors.shape[0], n_clusters))\n",
    "for i in range(n_clusters):\n",
    "    indicator_vectors[:, i] = (labels == i).astype(int)\n",
    "\n",
    "degrees = np.sum(affinity_matrix, axis=1)\n",
    "\n",
    "D_sqrt = np.diag(np.sqrt(degrees))\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    indicator_vectors[:, i] = D_sqrt @ indicator_vectors[:, i]\n",
    "    indicator_vectors[:, i] = indicator_vectors[:, i]\n",
    "    indicator_vectors[:, i] = indicator_vectors[:, i] / np.linalg.norm(indicator_vectors[:, i])\n",
    "\n",
    "# project indicator vectors onto the eigenvectors\n",
    "beta_K_by_K = (indicator_vectors.T @ eigenvectors[:,:n_clusters])\n",
    "\n",
    "\n",
    "combined_indicator_vectors = indicator_vectors @ beta_K_by_K\n",
    "for i in range(n_clusters):\n",
    "    combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] / np.linalg.norm(\n",
    "        combined_indicator_vectors[:, i])\n",
    "    for j in range(i):\n",
    "        combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] - (\n",
    "                    combined_indicator_vectors[:, j].T @ combined_indicator_vectors[:,\n",
    "                                                         i]) * combined_indicator_vectors[:, j]\n",
    "    \n",
    "for i in range(n_clusters):\n",
    "    combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] / np.linalg.norm(combined_indicator_vectors[:, i])\n",
    "    \n",
    "# compute the rayleigh quotients\n",
    "rayleigh_quotients = []\n",
    "for i in range(n_clusters):\n",
    "    indicator = combined_indicator_vectors[:, i]\n",
    "    val = (indicator.T @ normalized_laplacian @ indicator) / (indicator.T @ indicator)\n",
    "    rayleigh_quotients.append(val)\n",
    "\n",
    "# sort the rayleigh quotients\n",
    "sorted_rayleigh_quotients = np.sort(rayleigh_quotients)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bf9cbe7d9a07562"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_val_matrix_combined = eigenvectors[:,:n_clusters] - combined_indicator_vectors @ (np.conj(combined_indicator_vectors).T @ eigenvectors[:,:n_clusters]) \n",
    "# true val is frobenius norm of the matrix\n",
    "true_val_combined = np.linalg.norm(true_val_matrix_combined)**2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5204c201f59dcd06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_val_matrix = eigenvectors[:,:n_clusters] - indicator_vectors @ (np.conj(indicator_vectors).T @ eigenvectors[:,:n_clusters]) \n",
    "# true val is frobenius norm of the matrix\n",
    "true_val = np.linalg.norm(true_val_matrix)**2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1205b32c10326db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compute our recursive structure theorem bound by summing these bounds."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce629c2028dc2d26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "B_1 = rayleigh_quotients[0]/eigenvalues[1]\n",
    "B_2 = ((rayleigh_quotients[2] + rayleigh_quotients[1]) - 2*eigenvalues[1] + eigenvalues[3]*B_1)/(eigenvalues[3] - eigenvalues[1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5544a186661b05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We print out the out the true value using the indicator vectors and the combined indicator vectors to show that they produce the same value. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a6c42716aa1b47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"True Value: \", true_val / n_clusters)\n",
    "print(\"True Value from combined indicator vectors: \", true_val_combined / n_clusters)\n",
    "print(f\"Upper Bound from Recursive Structure Theorem: {(B_1 + B_2) / n_clusters}\")\n",
    "print(f\"Lower Bound from General Structure Theorem: {(np.sum(rayleigh_quotients)/eigenvalues[3]) / n_clusters}\")\n",
    "print(f\"Lower Bound from Structure Theorem: {(3*compute_k_way_estimate(normalized_laplacian, indicator_vectors, 3)/eigenvalues[3]) / n_clusters}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbe4aa96bdbe0d9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots for Synthetic Digraphs\n",
    "In this section we produce our plots for our two DSBMs. We first define some functions that we will use."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b82176991ec01e30"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "927611c23fdc74de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_volume(S: list, degrees: np.ndarray):\n",
    "    return np.sum([degrees[i] for i in S])\n",
    "\n",
    "#must use the adjacency matrix, not the hermitian adjacency matrix\n",
    "def compute_weight_between_sets(S1:list, S2:list, A: np.ndarray):\n",
    "    return np.sum([A[i,j] for i in S1 for j in S2])\n",
    "\n",
    "def Psi(partition: List[List[int]], A: np.ndarray, degrees: np.ndarray, C: List[tuple]):\n",
    "    k = len(partition)\n",
    "    volume = np.sum(degrees)\n",
    "    weight_total = 0\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "             if (i,j) not in C:\n",
    "                 weight = compute_weight_between_sets(partition[i], partition[j], A)\n",
    "                 weight_total += weight\n",
    "    return weight_total/volume\n",
    "\n",
    "\n",
    "def compute_theta(partition: List[List[int]], A: np.ndarray, degrees: np.ndarray, C: List[tuple]):\n",
    "    k = len(partition)\n",
    "    N = len(A)\n",
    "    weight_total = 0\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            if (i, j) in C:\n",
    "                vol_i = compute_volume(partition[i], degrees)\n",
    "                vol_j = compute_volume(partition[j], degrees)\n",
    "                weight = compute_weight_between_sets(partition[i], partition[j], A) / (vol_i + vol_j)\n",
    "                weight_total += weight\n",
    "    return weight_total\n",
    "\n",
    "\n",
    "def compute_new_bound(eigvals, ups):\n",
    "    b1 = (4 * ups - eigvals[0]) / (eigvals[1] - eigvals[0])\n",
    "    b2 = (4 * ups) / (eigvals[1])\n",
    "    return np.min([b1, b2])\n",
    "\n",
    "\n",
    "def compute_ls_bounds(eigvals, theta, k):\n",
    "    gamma = eigvals[1] / (1 - (4 / k) * theta)\n",
    "    bound_1 = 1 / gamma\n",
    "    bound_2 = 1 / (gamma - 1)\n",
    "    return bound_1, bound_2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb6d706d48e3ac54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_hermitian_adjacency_matrix(N, edges, root_of_unity: int = 4) -> np.array:\n",
    "    adjacency_matrix = np.zeros((N, N), dtype=np.complex128)\n",
    "    w_k = np.exp(2 * np.pi * 1j / root_of_unity)\n",
    "    w_k_conj = np.conj(w_k)\n",
    "    for edge in edges:\n",
    "        adjacency_matrix[edge] = w_k\n",
    "        adjacency_matrix[(edge[::-1])] = w_k_conj\n",
    "    return adjacency_matrix\n",
    "\n",
    "def get_adjacency_matrix(N, edges) -> np.array:\n",
    "    adjacency_matrix = np.zeros((N, N))\n",
    "    for edge in edges:\n",
    "        adjacency_matrix[edge] = 1\n",
    "    return adjacency_matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bcc842e5d52cbf7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A Cycle with 4 clusters, adding noise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a26cb7b957935e12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# construct directed graph with 10 cycle\n",
    "n = [0, 100, 200, 300, 400]\n",
    "N = n[-1]\n",
    "k = 4\n",
    "\n",
    "bounds = {}\n",
    "\n",
    "partition = []\n",
    "for i in range(k):\n",
    "    partition.append([j for j in range(n[i], n[i + 1])])\n",
    "### FOR CYCLE\n",
    "C = [(i, (i + 1) % k) for i in range(k)]\n",
    "C_path = [(i, i + 1) for i in range(k - 1)]\n",
    "\n",
    "F = np.array([[0.5, 1.0, 0.5, 0.0],\n",
    "              [0.0, 0.5, 1.0, 0.5],\n",
    "              [0.5, 0.0, 0.5, 1.0],\n",
    "              [1.0, 0.5, 0.0, 0.5]])\n",
    "\n",
    "def generate_P_cycle(eps=0.01):\n",
    "    P = [[eps, 1.0, eps, 1.0],\n",
    "         [1.0, eps, 1.0, eps],\n",
    "         [eps, 1.0, eps, 1.0],\n",
    "         [1.0, eps, 1.0, eps]]\n",
    "    return np.array(P)\n",
    "\n",
    "sample_size = 10 # SET TO 1 FOR TESTING\n",
    "\n",
    "true_vals = []\n",
    "new_bounds = []\n",
    "new_bound_rayleigh_quotients = []\n",
    "ls_bound_1s = []\n",
    "ls_bound_2s = []\n",
    "psis = []\n",
    "lambda_1s = []\n",
    "lambda_2s = []\n",
    "rayleigh_quotients = []\n",
    "\n",
    "for eps in np.arange(0, 0.2, 0.01):\n",
    "    P = generate_P_cycle(eps)\n",
    "    for _ in range(sample_size):\n",
    "        edges = []\n",
    "    \n",
    "        for i in range(k):\n",
    "            for j in range(k):\n",
    "                if i == j:\n",
    "                    prob_existing_edge = P[i, j]\n",
    "                    for index, u in enumerate(partition[i]):\n",
    "                        for v in partition[i][index + 1:]:\n",
    "                            if u == v:\n",
    "                                continue\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                if np.random.rand() <= F[i, j]:\n",
    "                                    edges.append((u, v))\n",
    "                                else:\n",
    "                                    edges.append((v, u))\n",
    "                else:\n",
    "                    prob_existing_edge = P[i, j]\n",
    "                    for u in partition[i]:\n",
    "                        for v in partition[j]:\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                if np.random.rand() <= F[i, j]:\n",
    "                                    edges.append((u, v))\n",
    "                                else:\n",
    "                                    edges.append((v, u))\n",
    "    \n",
    "    \n",
    "        A = get_hermitian_adjacency_matrix(N = N, edges = edges, root_of_unity=k)\n",
    "        degrees = np.sum(np.abs(A), axis=1)\n",
    "        D = np.diag(degrees)\n",
    "        D_sqrt = np.diag(np.sqrt(degrees))\n",
    "        D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "        norm_L = np.eye(int(N)) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "        \n",
    "        # construct indicator vector\n",
    "        ind_vector = np.zeros((N,), dtype = np.complex128)\n",
    "        for i in range(k):\n",
    "            ind_vector[n[i]:n[i+1]] = np.exp(-1j * 2 * np.pi * i / k)\n",
    "        ind_vector = D_sqrt @ ind_vector\n",
    "        ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "        \n",
    "        # compute rayleigh quotient of indicator vector\n",
    "        chi_rayleigh_quotient = np.real((np.conj(ind_vector).T @ norm_L @ ind_vector) / (np.conj(ind_vector).T @ ind_vector))\n",
    "        \n",
    "    \n",
    "        #Now computing using Laenen & Sun's choice of roots of unity\n",
    "        k_ls = int(np.ceil(2 * np.pi * k))\n",
    "        A_ls = get_hermitian_adjacency_matrix(N = N, edges = edges, root_of_unity=k_ls)\n",
    "        D_ls = np.sum(np.abs(A_ls), axis=1)\n",
    "        D_inv_sqrt_ls = np.diag(1 / np.sqrt(D_ls))\n",
    "        norm_L_ls = np.eye(int(N)) - D_inv_sqrt_ls @ A_ls @ D_inv_sqrt_ls\n",
    "    \n",
    "        eigvals, eigvecs = np.linalg.eigh(norm_L)\n",
    "        idx = eigvals.argsort()\n",
    "        eigvals = eigvals[idx]\n",
    "        eigvecs = eigvecs[:, idx]\n",
    "        ls_eigvals, ls_eigvecs = np.linalg.eigh(norm_L_ls)\n",
    "        # sort\n",
    "        idx = ls_eigvals.argsort()\n",
    "        ls_eigvals = ls_eigvals[idx]\n",
    "        ls_eigvecs = ls_eigvecs[:, idx]\n",
    "        A_standard = get_adjacency_matrix(N, edges)\n",
    "        ups = Psi(partition, A_standard, degrees, C)\n",
    "        theta = compute_theta(partition, A_standard, degrees, C_path)\n",
    "        \n",
    "        # computing true value\n",
    "        true_val = np.linalg.norm(eigvecs[:,0] - (np.conj(ind_vector).T @ eigvecs[:,0]) * ind_vector)**2\n",
    "        \n",
    "        new_bound_rayleigh_quotient = min((chi_rayleigh_quotient - eigvals[0])/ (eigvals[1] - eigvals[0]), chi_rayleigh_quotient / eigvals[1])\n",
    "        new_bound = compute_new_bound(eigvals, ups)\n",
    "        ls_bound_1, ls_bound_2 = compute_ls_bounds(ls_eigvals, theta, k)\n",
    "        \n",
    "        true_vals.append(true_val)\n",
    "        new_bounds.append(new_bound)\n",
    "        new_bound_rayleigh_quotients.append(new_bound_rayleigh_quotient)\n",
    "        ls_bound_1s.append(ls_bound_1)\n",
    "        ls_bound_2s.append(ls_bound_2)\n",
    "        psis.append(ups)\n",
    "        lambda_1s.append(eigvals[0])\n",
    "        lambda_2s.append(eigvals[1])\n",
    "        rayleigh_quotients.append(chi_rayleigh_quotient)\n",
    "\n",
    "    true_val = np.mean(true_vals)\n",
    "    new_bound = np.mean(new_bounds)\n",
    "    new_bound_rayleigh_quotient = np.mean(new_bound_rayleigh_quotients)\n",
    "    ls_bound_1 = np.mean(ls_bound_1s)\n",
    "    ls_bound_2 = np.mean(ls_bound_2s)\n",
    "    ups = np.mean(psis)\n",
    "    lambda_1 = np.mean(lambda_1s)\n",
    "    lambda_2 = np.mean(lambda_2s)\n",
    "    chi_rayleigh_quotient = np.mean(rayleigh_quotients)\n",
    "    \n",
    "    bounds[eps] = {'true_val': true_val,\n",
    "                   'new_bound': new_bound,\n",
    "                   'new_bound_rayleigh_quotient':new_bound_rayleigh_quotient,\n",
    "                   'ls_bound_1': ls_bound_1,\n",
    "                   'ls_bound_2': ls_bound_2,\n",
    "                   'Psi': ups,\n",
    "                   'lambda_1': eigvals[0],\n",
    "                   'lambda_2': eigvals[1],\n",
    "                   'rayleigh quotient': chi_rayleigh_quotient}\n",
    "bounds_df = pd.DataFrame(bounds).T\n",
    "bounds_df.columns = [r'$\\|f_1 - \\alpha \\chi\\|^2$',\n",
    "                     r'$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$',\n",
    "                      r'$\\frac{\\chi^* \\mathcal{L} \\chi - \\lambda_1}{\\lambda_2 - \\lambda_1}$',\n",
    "                     r'$\\frac{1}{\\eta_k}$',\n",
    "                     r'$\\frac{1}{\\eta_4-1}$',\n",
    "                     'ups',\n",
    "                     'lambda_1',\n",
    "                     'lambda_2',\n",
    "                     'rayleigh quotient']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f6b2f8305004f21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_for_plot = bounds_df[[r'$\\|f_1 - \\alpha \\chi\\|^2$', r'$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$', r'$\\frac{\\chi^* \\mathcal{L} \\chi - \\lambda_1}{\\lambda_2 - \\lambda_1}$', r'$\\frac{1}{\\eta_4-1}$']][\n",
    "    (bounds_df[r'$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$'] <= 0.8) + (bounds_df[r'$\\frac{1}{\\eta_4-1}$'] <= 0.8)].iloc[1:,:]\n",
    "df_for_plot.columns = ['Actual Error'+ r'\\n$\\|f_1 - \\alpha \\chi\\|^2$',  \n",
    "                       'Our bound ' + r'\\n$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$', \n",
    "                       'Our bound (Rayleigh Quotient) '+ r'\\n$\\frac{\\chi^* \\mathcal{L} \\chi - \\lambda_1}{\\lambda_2 - \\lambda_1}$',\n",
    "                       'LS bound ' + r'\\n$\\frac{1}{\\eta_4-1}$']\n",
    "\n",
    "# Plot the dataframe\n",
    "ax = df_for_plot.plot(\n",
    "     marker='o', linestyle='-', color=['purple','blue','green', 'red'],\n",
    "    figsize=(8\n",
    "             ,5), logy=True) #title=r'Cyclic DSBM (k=4)',\n",
    "\n",
    "# Set labels and grid\n",
    "plt.xlabel(r'Noise $\\epsilon$', fontsize=14)\n",
    "plt.ylabel(r'Error', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "legend_labels = [\n",
    "    'Actual',  \n",
    "    'Ours' + r' ($\\Psi$)', \n",
    "    'Ours (Rayleigh)',\n",
    "    'LS bound'\n",
    "    ]\n",
    "# Set custom legend with smaller font for equations\n",
    "plt.legend(\n",
    "    legend_labels, fontsize=14, loc='upper left', bbox_to_anchor=(1, 1),labelspacing=1.5, ncol=1)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('Figures/4_cluster_cycle_noise.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1331225872a16624"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph with 4 clusters in a path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e16fd9dd9bb435d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# construct directed graph with 10 cycle\n",
    "n = [0, 100, 200, 300, 400]\n",
    "N = n[-1]\n",
    "k = 4\n",
    "\n",
    "bounds = {}\n",
    "\n",
    "partition = []\n",
    "for i in range(k):\n",
    "    partition.append([j for j in range(n[i], n[i + 1])])\n",
    "### FOR CYCLE\n",
    "C = [(i, (i + 1) % k) for i in range(k)]\n",
    "C_path = [(i, i + 1) for i in range(k - 1)]\n",
    "\n",
    "F = np.array([[0.5, 1.0, 0.5, 0.5],\n",
    "              [0.0, 0.5, 1.0, 0.5],\n",
    "              [0.5, 0.0, 0.5, 1.0],\n",
    "              [0.5, 0.5, 0.0, 0.5]])\n",
    "\n",
    "def generate_P_cycle(eps=0.01):\n",
    "    P = [[eps, 1.0, eps, eps],\n",
    "         [1.0, eps, 1.0, eps],\n",
    "         [eps, 1.0, eps, 1.0],\n",
    "         [eps, eps, 1.0, eps]]\n",
    "    return np.array(P)\n",
    "\n",
    "sample_size = 10 # SET TO 1 FOR TESTING\n",
    "\n",
    "true_vals = []\n",
    "new_bounds = []\n",
    "new_bound_rayleigh_quotients = []\n",
    "ls_bound_1s = []\n",
    "ls_bound_2s = []\n",
    "psis = []\n",
    "lambda_1s = []\n",
    "lambda_2s = []\n",
    "rayleigh_quotients = []\n",
    "\n",
    "for eps in np.arange(0, 0.2, 0.01):\n",
    "    P = generate_P_cycle(eps)\n",
    "    for _ in range(sample_size):\n",
    "        edges = []\n",
    "    \n",
    "        for i in range(k):\n",
    "            for j in range(k):\n",
    "                if i == j:\n",
    "                    prob_existing_edge = P[i, j]\n",
    "                    for index, u in enumerate(partition[i]):\n",
    "                        for v in partition[i][index + 1:]:\n",
    "                            if u == v:\n",
    "                                continue\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                if np.random.rand() <= F[i, j]:\n",
    "                                    edges.append((u, v))\n",
    "                                else:\n",
    "                                    edges.append((v, u))\n",
    "                else:\n",
    "                    prob_existing_edge = P[i, j]\n",
    "                    for u in partition[i]:\n",
    "                        for v in partition[j]:\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                if np.random.rand() <= F[i, j]:\n",
    "                                    edges.append((u, v))\n",
    "                                else:\n",
    "                                    edges.append((v, u))\n",
    "    \n",
    "    \n",
    "        A = get_hermitian_adjacency_matrix(N = N, edges = edges, root_of_unity=k)\n",
    "        degrees = np.sum(np.abs(A), axis=1)\n",
    "        D = np.diag(degrees)\n",
    "        D_sqrt = np.diag(np.sqrt(degrees))\n",
    "        D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "        norm_L = np.eye(int(N)) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "        \n",
    "        # construct indicator vector\n",
    "        ind_vector = np.zeros((N,), dtype = np.complex128)\n",
    "        for i in range(k):\n",
    "            ind_vector[n[i]:n[i+1]] = np.exp(-1j * 2 * np.pi * i / k)\n",
    "        ind_vector = D_sqrt @ ind_vector\n",
    "        ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "        \n",
    "        # compute rayleigh quotient of indicator vector\n",
    "        chi_rayleigh_quotient = np.real((np.conj(ind_vector).T @ norm_L @ ind_vector) / (np.conj(ind_vector).T @ ind_vector))\n",
    "    \n",
    "\n",
    "        #Now computing using Laenen & Sun's choice of roots of unity\n",
    "        k_ls = int(np.ceil(2 * np.pi * k))\n",
    "        A_ls = get_hermitian_adjacency_matrix(N = N, edges = edges, root_of_unity=k_ls)\n",
    "        D_ls = np.sum(np.abs(A_ls), axis=1)\n",
    "        D_inv_sqrt_ls = np.diag(1 / np.sqrt(D_ls))\n",
    "        norm_L_ls = np.eye(int(N)) - D_inv_sqrt_ls @ A_ls @ D_inv_sqrt_ls\n",
    "    \n",
    "        eigvals, eigvecs = np.linalg.eigh(norm_L)\n",
    "        idx = eigvals.argsort()\n",
    "        eigvals = eigvals[idx]\n",
    "        eigvecs = eigvecs[:, idx]\n",
    "        ls_eigvals, ls_eigvecs = np.linalg.eigh(norm_L_ls)\n",
    "        # sort\n",
    "        idx = ls_eigvals.argsort()\n",
    "        ls_eigvals = ls_eigvals[idx]\n",
    "        ls_eigvecs = ls_eigvecs[:, idx]\n",
    "        A_standard = get_adjacency_matrix(N, edges)\n",
    "        ups = Psi(partition, A_standard, degrees, C)\n",
    "        theta = compute_theta(partition, A_standard, degrees, C_path)\n",
    "        \n",
    "        # computing true value\n",
    "        true_val = np.linalg.norm(eigvecs[:,0] - (np.conj(ind_vector).T @ eigvecs[:,0]) * ind_vector)**2\n",
    "    \n",
    "        new_bound_rayleigh_quotient = min((chi_rayleigh_quotient - eigvals[0])/ (eigvals[1] - eigvals[0]), chi_rayleigh_quotient / eigvals[1])\n",
    "        new_bound = compute_new_bound(eigvals, ups)\n",
    "        ls_bound_1, ls_bound_2 = compute_ls_bounds(ls_eigvals, theta, k)\n",
    "        \n",
    "        true_vals.append(true_val)\n",
    "        new_bounds.append(new_bound)\n",
    "        new_bound_rayleigh_quotients.append(new_bound_rayleigh_quotient)\n",
    "        ls_bound_1s.append(ls_bound_1)\n",
    "        ls_bound_2s.append(ls_bound_2)\n",
    "        psis.append(ups)\n",
    "        lambda_1s.append(eigvals[0])\n",
    "        lambda_2s.append(eigvals[1])\n",
    "        rayleigh_quotients.append(chi_rayleigh_quotient)\n",
    "\n",
    "    true_val = np.mean(true_vals)\n",
    "    new_bound = np.mean(new_bounds)\n",
    "    new_bound_rayleigh_quotient = np.mean(new_bound_rayleigh_quotients)\n",
    "    ls_bound_1 = np.mean(ls_bound_1s)\n",
    "    ls_bound_2 = np.mean(ls_bound_2s)\n",
    "    ups = np.mean(psis)\n",
    "    lambda_1 = np.mean(lambda_1s)\n",
    "    lambda_2 = np.mean(lambda_2s)\n",
    "    chi_rayleigh_quotient = np.mean(rayleigh_quotients)\n",
    "    \n",
    "    bounds[eps] = {'true_val': true_val,\n",
    "                   'new_bound': new_bound,\n",
    "                   'new_bound_rayleigh_quotient':new_bound_rayleigh_quotient,\n",
    "                   'ls_bound_1': ls_bound_1,\n",
    "                   'ls_bound_2': ls_bound_2,\n",
    "                   'Psi': ups,\n",
    "                   'lambda_1': eigvals[0],\n",
    "                   'lambda_2': eigvals[1],\n",
    "                   'rayleigh quotient': chi_rayleigh_quotient}\n",
    "bounds_df = pd.DataFrame(bounds).T\n",
    "bounds_df.columns = [r'$\\|f_1 - \\alpha \\chi\\|^2$',\n",
    "                     r'$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$',\n",
    "                      r'$\\frac{\\chi^* \\mathcal{L} \\chi - \\lambda_1}{\\lambda_2 - \\lambda_1}$',\n",
    "                     r'$\\frac{1}{\\eta_k}$',\n",
    "                     r'$\\frac{1}{\\eta_4-1}$',\n",
    "                     'ups',\n",
    "                     'lambda_1',\n",
    "                     'lambda_2',\n",
    "                     'rayleigh quotient']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c839bc71223f57ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_for_plot = bounds_df[[r'$\\|f_1 - \\alpha \\chi\\|^2$', r'$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$', r'$\\frac{\\chi^* \\mathcal{L} \\chi - \\lambda_1}{\\lambda_2 - \\lambda_1}$', r'$\\frac{1}{\\eta_4-1}$']][\n",
    "    (bounds_df[r'$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$'] <= 0.8) + (bounds_df[r'$\\frac{1}{\\eta_4-1}$'] <= 0.8)].iloc[1:,:]\n",
    "df_for_plot.columns = ['Actual Error'+ r'\\n$\\|f_1 - \\alpha \\chi\\|^2$',  \n",
    "                       'Our bound ' + r'\\n$\\frac{4 \\Psi - \\lambda_1}{\\lambda_2 - \\lambda_1}$', \n",
    "                       'Our bound (Rayleigh Quotient) '+ r'\\n$\\frac{\\chi^* \\mathcal{L} \\chi - \\lambda_1}{\\lambda_2 - \\lambda_1}$',\n",
    "                       'LS bound ' + r'\\n$\\frac{1}{\\eta_4-1}$']\n",
    "\n",
    "# Plot the dataframe\n",
    "ax = df_for_plot.plot(\n",
    "     marker='o', linestyle='-', color=['purple','blue','green', 'red'],\n",
    "    figsize=(8\n",
    "             ,5), logy=True) #title=r'Path DSBM (k=4)',\n",
    "\n",
    "# Set labels and grid\n",
    "plt.xlabel(r'Noise $\\epsilon$', fontsize=14)\n",
    "plt.ylabel(r'Error', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "legend_labels = [\n",
    "    'Actual',  \n",
    "    'Ours' + r' ($\\Psi$)', \n",
    "    'Ours (Rayleigh)',\n",
    "    'LS bound'\n",
    "    ]\n",
    "\n",
    "# Set custom legend with smaller font for equations\n",
    "plt.legend(\n",
    "    legend_labels, fontsize=14, loc='upper left', bbox_to_anchor=(1, 1),labelspacing=1.5, ncol=1)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('Figures/4_cluster_path_noise.png',bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "872c0e1cfc9bb8c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# YellowStone Graph\n",
    "In this section we produce the plot the bounds and some figures for our yellowstone graph. Since k is small for this graph (and the others), we will search for the best permutation of the clusters by brute force for computing $\\Psi$ and $\\eta$."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f9b3cae8f397b70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Nodes and edges for the second image\n",
    "nodes = [\n",
    "    \"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\", \"Pika\", \"Red-breasted\\n nuthatch\",\n",
    "    \"Pacific\\n tree frog\", \"Edith's\\n checkerspot\", \"Douglas'\\n squirrel\", \"Mule deer\",\n",
    "    \"Black-tipped\\n jackrabbit\", \"Pine marten\", \"Western\\n whiptail\", \"Raven\",\n",
    "    \"Ringtail\", \"Coyote\", \"Mountain\\n lion\", \"Bobcat\"\n",
    "]\n",
    "\n",
    "# Initialize the adjacency matrix with zeros\n",
    "adj_matrix = np.zeros((len(nodes), len(nodes)), dtype=int)\n",
    "\n",
    "# Map the nodes to matrix index\n",
    "index_map = {species: i for i, species in enumerate(nodes)}\n",
    "\n",
    "partition = {\"Producers and Decomposer\": [\"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\"],\n",
    "             \"Primary Consumers\": [\"Pika\", \"Red-breasted\\n nuthatch\", \"Pacific\\n tree frog\", \"Edith's\\n checkerspot\",\n",
    "                                   \"Douglas'\\n squirrel\", \"Mule deer\"],\n",
    "             \"Secondary Consumers\": [\"Black-tipped\\n jackrabbit\", \"Pine marten\", \"Western\\n whiptail\", \"Raven\", \"Ringtail\"],\n",
    "             \"Tertiary Consumers\": [\"Coyote\", \"Mountain\\n lion\", \"Bobcat\"]}\n",
    "\n",
    "partition_numbered = [[index_map[species] for species in community] for community in partition.values()]\n",
    "# Manually add edges based on the image (directed edges where energy is transferred)\n",
    "edges = [\n",
    "    (\"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\", \"Pika\"),\n",
    "    (\"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\", \"Red-breasted\\n nuthatch\"),\n",
    "    (\"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\", \"Pacific\\n tree frog\"),\n",
    "    (\"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\", \"Edith's\\n checkerspot\"),\n",
    "    (\"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\", \"Douglas'\\n squirrel\"),\n",
    "    (\"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\", \"Mule deer\"),\n",
    "\n",
    "    (\"Pika\", \"Ringtail\"),\n",
    "    (\"Pika\", \"Western\\n whiptail\"),\n",
    "    (\"Pika\", \"Raven\"),\n",
    "    (\"Pika\", \"Black-tipped\\n jackrabbit\"),\n",
    "    (\"Pika\", \"Pine marten\"),\n",
    "\n",
    "    (\"Red-breasted\\n nuthatch\", \"Western\\n whiptail\"),\n",
    "\n",
    "    (\"Pacific\\n tree frog\", \"Ringtail\"),\n",
    "    (\"Pacific\\n tree frog\", \"Western\\n whiptail\"),\n",
    "    (\"Pacific\\n tree frog\", \"Raven\"),\n",
    "    (\"Pacific\\n tree frog\", \"Black-tipped\\n jackrabbit\"),\n",
    "    (\"Pacific\\n tree frog\", \"Pine marten\"),\n",
    "\n",
    "    (\"Edith's\\n checkerspot\", \"Western\\n whiptail\"),\n",
    "    (\"Edith's\\n checkerspot\", \"Raven\"),\n",
    "    (\"Edith's\\n checkerspot\", \"Black-tipped\\n jackrabbit\"),\n",
    "\n",
    "    (\"Douglas'\\n squirrel\", \"Ringtail\"),\n",
    "    (\"Douglas'\\n squirrel\", \"Raven\"),\n",
    "    (\"Douglas'\\n squirrel\", \"Black-tipped\\n jackrabbit\"),\n",
    "    (\"Douglas'\\n squirrel\", \"Pine marten\"),\n",
    "\n",
    "    (\"Mule deer\", \"Mountain\\n lion\"),\n",
    "    (\"Mule deer\", \"Coyote\"),\n",
    "\n",
    "    (\"Ringtail\", \"Coyote\"),\n",
    "    (\"Ringtail\", \"Mountain\\n lion\"),\n",
    "    (\"Ringtail\", \"Bobcat\"),\n",
    "\n",
    "    (\"Western\\n whiptail\", \"Mountain\\n lion\"),\n",
    "    (\"Western\\n whiptail\", \"Bobcat\"),\n",
    "    (\"Western\\n whiptail\", \"Coyote\"),\n",
    "\n",
    "    (\"Black-tipped\\n jackrabbit\", \"Mountain\\n lion\"),\n",
    "    (\"Black-tipped\\n jackrabbit\", \"Coyote\"),\n",
    "    (\"Black-tipped\\n jackrabbit\", \"Bobcat\"),\n",
    "\n",
    "    (\"Pine marten\", \"Mountain\\n lion\"),\n",
    "    (\"Pine marten\", \"Bobcat\")\n",
    "]\n",
    "\n",
    "# Now we can fill the adjacency matrix again based on these edges\n",
    "for source, target in edges:\n",
    "    adj_matrix[index_map[source], index_map[target]] = 1\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "adj_matrix_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges to the graph from the previous trophic relationships\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = {\n",
    "    \"Plants,\\n Flowers,\\n Nuts,\\n Seeds,\\n Fruit,\\n Insects\": (0, 6),\n",
    "\n",
    "    \"Pika\": (-6, 4), \"Red-breasted\\n nuthatch\": (-3, 4), \"Pacific\\n tree frog\": (0, 4), \n",
    "    \"Edith's\\n checkerspot\": (3, 4), \"Douglas'\\n squirrel\": (6, 4), \"Mule deer\": (9, 4),\n",
    "\n",
    "    \"Black-tipped\\n jackrabbit\": (-7, 2), \"Pine marten\": (-4, 2), \n",
    "    \"Western\\n whiptail\": (-1, 2), \"Raven\": (2, 2), \"Ringtail\": (5, 2),\n",
    "\n",
    "    \"Coyote\": (-5, 0), \"Mountain\\n lion\": (-2, 0), \"Bobcat\": (1, 0)\n",
    "}\n",
    "\n",
    "\n",
    "# Color mapping for different communities\n",
    "color_map = {\n",
    "    \"Producers and Decomposer\": \"green\",\n",
    "    \"Primary Consumers\": \"blue\",\n",
    "    \"Secondary Consumers\": \"orange\",\n",
    "    \"Tertiary Consumers\": \"red\"\n",
    "}\n",
    "\n",
    "# Assign colors based on community\n",
    "node_colors = []\n",
    "for node in G.nodes():\n",
    "    for community, members in partition.items():\n",
    "        if node in members:\n",
    "            node_colors.append(color_map[community])\n",
    "\n",
    "# Plot the graph using networkx\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(G, pos, with_labels=True, node_size=5000, \n",
    "                 font_size=10, font_color='black', font_weight='bold',node_color='white', edgecolors=node_colors, arrows=True, alpha=0.65)\n",
    "\n",
    "# Display the plot\n",
    "#plt.title('Directed Graph of Yellowstone Trophic Cascade')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('Figures/YellowstoneTrophicCascade2.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1358c90a795e117"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute hermitian adjacency matrix\n",
    "k = 4\n",
    "k_ls = int(np.ceil(2 * np.pi * k))\n",
    "A = adj_matrix * np.exp(1j * 2 * np.pi / 4) + adj_matrix.T * np.exp(-1j * 2 * np.pi / 4)\n",
    "A_ls = adj_matrix * np.exp(1j * 2 * np.pi / k_ls) + adj_matrix.T * np.exp(-1j * 2 * np.pi / k_ls)\n",
    "# compute degree matrix\n",
    "degrees = np.sum(np.abs(A), axis=1)\n",
    "D = np.diag(degrees)\n",
    "D_sqrt = np.diag(np.sqrt(degrees))\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "norm_L = np.eye(len(nodes)) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "\n",
    "#Compute indicator vector\n",
    "ind_vector = np.zeros((len(nodes),), dtype = np.complex128)\n",
    "for i in range(k):\n",
    "    for node in partition[list(partition.keys())[i]]:\n",
    "        ind_vector[index_map[node]] = np.exp(-1j * 2 * np.pi * i / k)\n",
    "ind_vector = D_sqrt @ ind_vector\n",
    "ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "\n",
    "rayleigh_quotient = np.real((np.conj(ind_vector).T @ norm_L @ ind_vector) / (np.conj(ind_vector).T @ ind_vector))\n",
    "\n",
    "#Now computing using Laenen & Sun's choice of roots of unity\n",
    "D_ls = np.sum(np.abs(A_ls), axis=1)\n",
    "D_inv_sqrt_ls = np.diag(1 / np.sqrt(D_ls))\n",
    "norm_L_ls = np.eye(len(nodes)) - D_inv_sqrt_ls @ A_ls @ D_inv_sqrt_ls\n",
    "evals, evecs = np.linalg.eigh(norm_L)\n",
    "evals_ls, evecs_ls = np.linalg.eigh(norm_L_ls)\n",
    "# plot first evec\n",
    "\n",
    "thetas = []\n",
    "for perm in itertools.permutations(range(4)):\n",
    "    C = [(perm[i], perm[i + 1]) for i in range(3)]\n",
    "    theta = compute_theta(partition_numbered, adj_matrix, degrees, C)\n",
    "    thetas.append(theta)\n",
    "\n",
    "theta = max(thetas)\n",
    "max_perm_theta = list(itertools.permutations(range(4)))[np.argmax(thetas)]\n",
    "\n",
    "C = [(0, 1), (1, 2), (2, 3), (3, 0)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f33f709bbd57fc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.plot(evecs[:, 0].real, evecs[:, 0].imag, '+', label='standard', alpha=0.5)\n",
    "# add labels\n",
    "for i, txt in enumerate(nodes):\n",
    "    plt.annotate(txt, (evecs[i, 0].real, evecs[i, 0].imag))\n",
    "\n",
    "# colour by community\n",
    "for i, community in enumerate(partition_numbered):\n",
    "    plt.plot(evecs[community, 0].real, evecs[community, 0].imag, 'o', label=f'community {i}', alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4fafae33ad69817"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_val = np.linalg.norm(evecs[:,0] - (np.conj(ind_vector).T @ evecs[:,0]) * ind_vector)**2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39f6bb028aa7dd22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theta = compute_theta(partition_numbered, adj_matrix, degrees, [(i, i + 1) for i in range(4)])\n",
    "ls_1, ls_2 = compute_ls_bounds(evals_ls, theta, k)\n",
    "print(\"Theta is \", theta)\n",
    "print(\"1/eta_k is \", ls_1)\n",
    "print(\"1/(eta_k-1) is \", ls_2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43cfb16652e27e43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "psi = Psi(partition_numbered, adj_matrix, degrees, C)\n",
    "new_bound = compute_new_bound(evals, psi)\n",
    "new_bound_with_rayleigh_quotient = (rayleigh_quotient - evals[0])/(evals[1] - evals[0])\n",
    "print(\"Rayleigh Quotient is \", rayleigh_quotient)\n",
    "print(\"Psi is \", psi)\n",
    "print(\"True value is \", true_val)\n",
    "print(\"New bound is \",new_bound)\n",
    "print(\"New bound with rayleigh quotient is \", new_bound_with_rayleigh_quotient)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44281a71888f97e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Covid Infection Graph\n",
    "In this section we compute the covid infection graph. Since the graph fits a perfect 4-cycle, we can state exactly what the cycle C should be. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1e871c897ed5d92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "patient_info_df = pd.read_csv(\"Data/PatientInfo.csv\")\n",
    "patient_info_df.head()\n",
    "edges_df = patient_info_df[[\"infected_by\", \"patient_id\"]].dropna(subset=[\"infected_by\"])\n",
    "edges_df.columns = [\"source\", \"target\"]\n",
    "edges_df = edges_df.astype(str)\n",
    "# create adjacency matrix\n",
    "index = list(set(edges_df[\"source\"].values) | set(edges_df[\"target\"].values))\n",
    "index.sort()\n",
    "adjacency_matrix = np.zeros((len(index), len(index)))\n",
    "for i, row in edges_df.iterrows():\n",
    "    source = row[\"source\"]\n",
    "    target = row[\"target\"]\n",
    "    source_index = index.index(source)\n",
    "    target_index = index.index(target)\n",
    "    adjacency_matrix[source_index, target_index] = 1\n",
    "adjacency_matrix_df = pd.DataFrame(adjacency_matrix, index=index, columns=index)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232fadba340d2e7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def largest_connected_component_adjacency(df):\n",
    "    # Convert the DataFrame to a NumPy array\n",
    "    adj_matrix = df\n",
    "\n",
    "    # Create a directed graph from the adjacency matrix\n",
    "    G = nx.from_pandas_adjacency(adj_matrix, create_using=nx.DiGraph)\n",
    "\n",
    "    # Find the largest strongly connected component\n",
    "    largest_wcc = max(nx.weakly_connected_components(G), key=len)\n",
    "\n",
    "    # Create a subgraph from the largest SCC\n",
    "    largest_wcc_subgraph = G.subgraph(largest_wcc)\n",
    "\n",
    "    # Get the adjacency matrix of the largest SCC subgraph\n",
    "    largest_wcc_adj_matrix = nx.to_numpy_array(largest_wcc_subgraph, nodelist=sorted(largest_wcc))\n",
    "\n",
    "    # Create a new DataFrame for the adjacency matrix of the largest SCC\n",
    "    largest_wcc_df = pd.DataFrame(largest_wcc_adj_matrix,\n",
    "                                  index=sorted(largest_wcc),\n",
    "                                  columns=sorted(largest_wcc))\n",
    "\n",
    "    return largest_wcc_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b444584a3aef6be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "largest_wcc_df = largest_connected_component_adjacency(adjacency_matrix_df)\n",
    "# draw graph\n",
    "G = nx.from_pandas_adjacency(largest_wcc_df, create_using=nx.DiGraph)\n",
    "\n",
    "k = 4\n",
    "herm_A = np.exp(1j * 2 * np.pi / k) * largest_wcc_df.values + np.exp(-1j * 2 * np.pi / k) * largest_wcc_df.values.T\n",
    "degrees = np.sum(np.abs(herm_A), axis=1)\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "norm_L = np.eye(len(herm_A)) - D_inv_sqrt @ herm_A @ D_inv_sqrt\n",
    "\n",
    "k_ls = int(np.ceil(2 * np.pi * k))\n",
    "herm_A_ls = np.exp(1j * 2 * np.pi / k_ls) * largest_wcc_df.values + np.exp(\n",
    "    -1j * 2 * np.pi / k_ls) * largest_wcc_df.values.T\n",
    "degrees_ls = np.sum(np.abs(herm_A_ls), axis=1)\n",
    "D_inv_sqrt_ls = np.diag(1 / np.sqrt(degrees_ls))\n",
    "norm_L_ls = np.eye(len(herm_A_ls)) - D_inv_sqrt_ls @ herm_A_ls @ D_inv_sqrt_ls\n",
    "\n",
    "# Compute Eigenvectors and Eigenvalues\n",
    "e_vals, e_vecs = np.linalg.eigh(norm_L)\n",
    "e_vals_ls, e_vecs_ls = np.linalg.eigh(norm_L_ls)\n",
    "\n",
    "\n",
    "datapoints = np.column_stack((D_inv_sqrt @ e_vecs[:, 0].real, D_inv_sqrt @ e_vecs[:, 0].imag))\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(datapoints)\n",
    "partition_numbered = [np.where(kmeans.labels_ == i)[0] for i in range(4)]\n",
    "\n",
    "color_map = []\n",
    "for i, node in enumerate(largest_wcc_df.index):\n",
    "    if i in partition_numbered[0]:\n",
    "        color_map.append('blue')\n",
    "    elif i in partition_numbered[1]:\n",
    "        color_map.append('red')\n",
    "    elif i in partition_numbered[2]:\n",
    "        color_map.append('green')\n",
    "    elif i in partition_numbered[3]:\n",
    "        color_map.append('yellow')\n",
    "    else:\n",
    "        color_map.append('black')\n",
    "G = nx.from_pandas_adjacency(largest_wcc_df, create_using=nx.DiGraph)\n",
    "pos = {}\n",
    "partition_sizes = [len(partition) for partition in partition_numbered]\n",
    "scale = 60\n",
    "for i, node_number in enumerate(largest_wcc_df.index):\n",
    "    if i in partition_numbered[0]:\n",
    "        index_in_partition = np.where(partition_numbered[0] == i)[0][0]\n",
    "        pos[node_number] = (10 + scale * index_in_partition / partition_sizes[0], 0)\n",
    "    elif i in partition_numbered[1]:\n",
    "        index_in_partition = np.where(partition_numbered[1] == i)[0][0]\n",
    "        pos[node_number] = (0, 10 + scale * index_in_partition / partition_sizes[0])\n",
    "    elif i in partition_numbered[2]:\n",
    "        index_in_partition = np.where(partition_numbered[2] == i)[0][0]\n",
    "        pos[node_number] = (0, -10 + scale * index_in_partition / partition_sizes[0])\n",
    "    elif i in partition_numbered[3]:\n",
    "        index_in_partition = np.where(partition_numbered[3] == i)[0][0]\n",
    "        pos[node_number] = (-10 + scale * index_in_partition / partition_sizes[0], 0)\n",
    "    else:\n",
    "        pos[node_number] = (0, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(G, pos, node_color=color_map, with_labels=False, node_size=15, width=0.5, connectionstyle='arc3, rad = 0.1')\n",
    "#plt.title(\"Partitioning of Largest Connected Component of DS4C Infection Network\")\n",
    "plt.savefig('Figures/DS4CInfectionNetwork.png', bbox_inches='tight')\n",
    "# compute weight between every pair of clusters\n",
    "\n",
    "C = [(2, 0), (0, 1), (1, 3), (3, 2)]\n",
    "\n",
    "theta = compute_theta(partition_numbered, largest_wcc_df.values, degrees, C)\n",
    "compute_ls_bounds(e_vals_ls, theta, k)\n",
    "eta_k = e_vals_ls[1] / (1 - (4 / k) * theta)\n",
    "\n",
    "print(\"Theta\", theta)\n",
    "print(\"eta_k\", e_vals_ls[1] / (1 - (4 / k) * theta))\n",
    "print(\"1/eta_k\", 1/eta_k)\n",
    "print(\"1/(eta_k-1)\", 1/(eta_k - 1))\n",
    "\n",
    "print(\"Psi\", Psi(partition_numbered, largest_wcc_df.values, degrees, C))\n",
    "print(\"New bound\", compute_new_bound(e_vals, Psi(partition_numbered, largest_wcc_df.values, degrees, C)))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0292a7fd84aaa08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ythan Estuary\n",
    "Using k = 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9669b943cdf51223"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# import edge list from http://cosinproject.eu/extra/data/foodwebs/ythan.txt\n",
    "\n",
    "urllib.request.urlretrieve(\"http://cosinproject.eu/extra/data/foodwebs/ythan.txt\", \"Data/ythan.txt\")\n",
    "# construct adjacency matrix\n",
    "with open(\"Data/ythan.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    edges = [tuple(map(int, line.strip().split())) for line in lines]\n",
    "\n",
    "edges_df = pd.DataFrame(edges, columns=[\"source\", \"target\"])\n",
    "edges_df_unweighted = edges_df.applymap(int)\n",
    "edges_df_unweighted.head(10)\n",
    "# convert edges_df_unweighted to adjacency matrix\n",
    "index = list(set(edges_df_unweighted[\"source\"].values) | set(edges_df_unweighted[\"target\"].values))\n",
    "index.sort()\n",
    "adj_matrix = np.zeros((len(index), len(index)))\n",
    "for i, row in edges_df_unweighted.iterrows():\n",
    "    source = row[\"source\"]\n",
    "    target = row[\"target\"]\n",
    "    source_index = index.index(source)\n",
    "    target_index = index.index(target)\n",
    "    adj_matrix[source_index, target_index] = 1\n",
    "\n",
    "k = 4\n",
    "k_ls = int(np.ceil(2 * np.pi * k))\n",
    "herm_A = np.exp(1j * 2 * np.pi / k) * adj_matrix + np.exp(-1j * 2 * np.pi / k) * adj_matrix.T\n",
    "herm_A_ls = np.exp(1j * 2 * np.pi / k_ls) * adj_matrix + np.exp(-1j * 2 * np.pi / k_ls) * adj_matrix.T\n",
    "degrees = np.sum(np.abs(herm_A), axis=1)\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "D_sqrt = np.diag(np.sqrt(degrees))\n",
    "norm_L = np.eye(len(adj_matrix)) - D_inv_sqrt @ herm_A @ D_inv_sqrt\n",
    "norm_L_ls = np.eye(len(adj_matrix)) - D_inv_sqrt @ herm_A_ls @ D_inv_sqrt\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eigh(norm_L)\n",
    "idx = eigvals.argsort()\n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "\n",
    "eigvals_ls, eigvecs_ls = np.linalg.eigh(norm_L_ls)\n",
    "idx = eigvals_ls.argsort()\n",
    "eigvals_ls = eigvals_ls[idx]\n",
    "eigvecs_ls = eigvecs_ls[:, idx]\n",
    "\n",
    "# cluster using first eigenvector\n",
    "datapoints = np.column_stack((D_inv_sqrt @ eigvecs[:, 0].real, D_inv_sqrt @ eigvecs[:, 0].imag))\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(datapoints)\n",
    "partition_numbered = [np.where(kmeans.labels_ == i)[0] for i in range(k)]\n",
    "\n",
    "rayleigh_quotients_all = []\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    # construct indicator vector of clusters\n",
    "    ind_vector = np.zeros((len(adj_matrix),), dtype=np.complex128)\n",
    "\n",
    "    for i, cluster in enumerate(partition_numbered):\n",
    "        ind_vector[cluster] = np.exp(2 * np.pi * 1j * perm[i] / k)\n",
    "\n",
    "    ind_vector = D_sqrt @ ind_vector\n",
    "    ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "\n",
    "    # rotate indicator vector to align with first eigenvector\n",
    "    alpha = np.conj(ind_vector).T @ eigvecs[:, 0]\n",
    "    ind_vector = alpha * ind_vector\n",
    "    ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "\n",
    "    rayleigh_quotients_all.append(np.real(np.conj(ind_vector).T @ norm_L @ ind_vector))\n",
    "\n",
    "\n",
    "# set indicator vector to be the one with the minimum rayleigh quotient\n",
    "min_perm = list(itertools.permutations(range(k)))[rayleigh_quotients_all.index(min(rayleigh_quotients_all))]\n",
    "min_ind_vector = np.zeros((len(adj_matrix),), dtype=np.complex128)\n",
    "\n",
    "for i, cluster in enumerate(partition_numbered):\n",
    "    min_ind_vector[cluster] = np.exp(2 * np.pi * 1j * min_perm[i] / k)\n",
    "\n",
    "min_ind_vector = D_sqrt @ min_ind_vector\n",
    "min_ind_vector = min_ind_vector / np.linalg.norm(min_ind_vector)\n",
    "\n",
    "# compute Psi\n",
    "Psis = []\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    C = [(perm[i], perm[i + 1]) for i in range(k - 1)] + [(perm[k - 1], perm[0])]\n",
    "    Psis.append(Psi(partition_numbered, adj_matrix, degrees, C))\n",
    "\n",
    "min_perm_psi = list(itertools.permutations(range(k)))[Psis.index(min(Psis))]\n",
    "\n",
    "# rotate indicator vector to align with first eigenvector\n",
    "alpha = np.conj(min_ind_vector).T @ eigvecs[:, 0]\n",
    "min_ind_vector = alpha * min_ind_vector\n",
    "\n",
    "thetas = []\n",
    "\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    C = [(perm[i], perm[i + 1]) for i in range(len(perm) - 1)]\n",
    "    C.append((perm[-1], perm[0]))\n",
    "    theta = compute_theta(partition_numbered, adj_matrix, degrees, C)\n",
    "    thetas.append(theta)\n",
    "    \n",
    "max_perm_theta = list(itertools.permutations(range(k)))[thetas.index(max(thetas))]\n",
    "print(\"Max perm theta \", max_perm_theta)\n",
    "C = [(max_perm_theta[i], max_perm_theta[i + 1]) for i in range(len(max_perm_theta) - 1)]\n",
    "theta = compute_theta(partition_numbered, adj_matrix, degrees, C)\n",
    "\n",
    "compute_ls_bounds(eigvals_ls, theta, k)\n",
    "eigvals_ls[1] / (1 - (4 / k) * theta)\n",
    "eta = eigvals_ls[1] / (1 - (4 / k) * theta)\n",
    "print(\"Theta\", theta)\n",
    "print(\"1/eta_k\", 1 / eta)\n",
    "print(\"1/(eta_k-1)\", 1 / (eta - 1))\n",
    "print(\"Psi\", min(Psis))\n",
    "print(\"rayleigh quotient\", min(rayleigh_quotients_all))\n",
    "print(\"Our bound (Rayleigh Quotient) \",(min(rayleigh_quotients_all) - eigvals[0]) / (eigvals[1] - eigvals[0]))\n",
    "print(\"Our bound (Psi) \", (4*min(Psis) - eigvals[0])/ (eigvals[1] - eigvals[0]))\n",
    "print(\"True value \", np.linalg.norm(min_ind_vector - eigvecs[:, 0]) ** 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e59994ebedf3a90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# St. Martins Island\n",
    "Using k = 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e725ddd243b5258a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "urllib.request.urlretrieve(\"http://cosinproject.eu/extra/data/foodwebs/stmartin.txt\", \"Data/stmartin.txt\")\n",
    "# construct adjacency matrix\n",
    "with open(\"Data/stmartin.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    edges = [tuple(map(int, line.strip().split())) for line in lines]\n",
    "\n",
    "edges_df = pd.DataFrame(edges, columns=[\"source\", \"target\"])\n",
    "edges_df_unweighted = edges_df.applymap(int)\n",
    "edges_df_unweighted.head(10)\n",
    "# convert edges_df_unweighted to adjacency matrix\n",
    "index = list(set(edges_df_unweighted[\"source\"].values) | set(edges_df_unweighted[\"target\"].values))\n",
    "index.sort()\n",
    "adj_matrix = np.zeros((len(index), len(index)))\n",
    "for i, row in edges_df_unweighted.iterrows():\n",
    "    source = row[\"source\"]\n",
    "    target = row[\"target\"]\n",
    "    source_index = index.index(source)\n",
    "    target_index = index.index(target)\n",
    "    adj_matrix[source_index, target_index] = 1\n",
    "\n",
    "k = 4\n",
    "k_ls = int(np.ceil(2 * np.pi * k))\n",
    "herm_A = np.exp(1j * 2 * np.pi / k) * adj_matrix + np.exp(-1j * 2 * np.pi / k) * adj_matrix.T\n",
    "herm_A_ls = np.exp(1j * 2 * np.pi / k_ls) * adj_matrix + np.exp(-1j * 2 * np.pi / k_ls) * adj_matrix.T\n",
    "degrees = np.sum(np.abs(herm_A), axis=1)\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "D_sqrt = np.diag(np.sqrt(degrees))\n",
    "norm_L = np.eye(len(adj_matrix)) - D_inv_sqrt @ herm_A @ D_inv_sqrt\n",
    "norm_L_ls = np.eye(len(adj_matrix)) - D_inv_sqrt @ herm_A_ls @ D_inv_sqrt\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eigh(norm_L)\n",
    "idx = eigvals.argsort()\n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "\n",
    "eigvals_ls, eigvecs_ls = np.linalg.eigh(norm_L_ls)\n",
    "idx = eigvals_ls.argsort()\n",
    "eigvals_ls = eigvals_ls[idx]\n",
    "eigvecs_ls = eigvecs_ls[:, idx]\n",
    "\n",
    "# cluster using first eigenvector\n",
    "datapoints = np.column_stack((D_inv_sqrt @ eigvecs[:, 0].real, D_inv_sqrt @ eigvecs[:, 0].imag))\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(datapoints)\n",
    "partition_numbered = [np.where(kmeans.labels_ == i)[0] for i in range(k)]\n",
    "\n",
    "rayleigh_quotients_all = []\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    # construct indicator vector of clusters\n",
    "    ind_vector = np.zeros((len(adj_matrix),), dtype=np.complex128)\n",
    "\n",
    "    for i, cluster in enumerate(partition_numbered):\n",
    "        ind_vector[cluster] = np.exp(2 * np.pi * 1j * perm[i] / k)\n",
    "\n",
    "    ind_vector = D_sqrt @ ind_vector\n",
    "    ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "\n",
    "    # rotate indicator vector to align with first eigenvector\n",
    "    alpha = np.conj(ind_vector).T @ eigvecs[:, 0]\n",
    "    ind_vector = alpha * ind_vector\n",
    "    ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "\n",
    "    rayleigh_quotients_all.append(np.real(np.conj(ind_vector).T @ norm_L @ ind_vector))\n",
    "\n",
    "\n",
    "# set indicator vector to be the one with the minimum rayleigh quotient\n",
    "min_perm = list(itertools.permutations(range(k)))[rayleigh_quotients_all.index(min(rayleigh_quotients_all))]\n",
    "min_ind_vector = np.zeros((len(adj_matrix),), dtype=np.complex128)\n",
    "\n",
    "for i, cluster in enumerate(partition_numbered):\n",
    "    min_ind_vector[cluster] = np.exp(2 * np.pi * 1j * min_perm[i] / k)\n",
    "\n",
    "min_ind_vector = D_sqrt @ min_ind_vector\n",
    "min_ind_vector = min_ind_vector / np.linalg.norm(min_ind_vector)\n",
    "\n",
    "# compute Psi\n",
    "Psis = []\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    C = [(perm[i], perm[i + 1]) for i in range(k - 1)] + [(perm[k - 1], perm[0])]\n",
    "    Psis.append(Psi(partition_numbered, adj_matrix, degrees, C))\n",
    "\n",
    "min_perm_psi = list(itertools.permutations(range(k)))[Psis.index(min(Psis))]\n",
    "\n",
    "# rotate indicator vector to align with first eigenvector\n",
    "alpha = np.conj(min_ind_vector).T @ eigvecs[:, 0]\n",
    "min_ind_vector = alpha * min_ind_vector\n",
    "\n",
    "thetas = []\n",
    "\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    C = [(perm[i], perm[i + 1]) for i in range(len(perm) - 1)]\n",
    "    C.append((perm[-1], perm[0]))\n",
    "    theta = compute_theta(partition_numbered, adj_matrix, degrees, C)\n",
    "    thetas.append(theta)\n",
    "    \n",
    "max_perm_theta = list(itertools.permutations(range(k)))[thetas.index(max(thetas))]\n",
    "print(\"Max perm theta \", max_perm_theta)\n",
    "C = [(max_perm_theta[i], max_perm_theta[i + 1]) for i in range(len(max_perm_theta) - 1)]\n",
    "theta = compute_theta(partition_numbered, adj_matrix, degrees, C)\n",
    "\n",
    "compute_ls_bounds(eigvals_ls, theta, k)\n",
    "eigvals_ls[1] / (1 - (4 / k) * theta)\n",
    "eta = eigvals_ls[1] / (1 - (4 / k) * theta)\n",
    "print(\"Theta\", theta)\n",
    "print(\"1/eta_k\", 1 / eta)\n",
    "print(\"1/(eta_k-1)\", 1 / (eta - 1))\n",
    "print(\"Psi\", min(Psis))\n",
    "print(\"rayleigh quotient\", min(rayleigh_quotients_all))\n",
    "print(\"Our bound (Rayleigh Quotient) \",(min(rayleigh_quotients_all) - eigvals[0]) / (eigvals[1] - eigvals[0]))\n",
    "print(\"Our bound (Psi) \", (4*min(Psis) - eigvals[0])/ (eigvals[1] - eigvals[0]))\n",
    "print(\"True value \", np.linalg.norm(min_ind_vector - eigvecs[:, 0]) ** 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ddd04d582edbded"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# St. Marks Seagrass\n",
    "Using k = 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc822f83272005db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "urllib.request.urlretrieve(\"http://cosinproject.eu/extra/data/foodwebs/seagrass.txt\", \"Data/seagrass.txt\")\n",
    "# construct adjacency matrix\n",
    "with open(\"Data/seagrass.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    edges = [tuple(map(int, line.strip().split())) for line in lines]\n",
    "\n",
    "edges_df = pd.DataFrame(edges, columns=[\"source\", \"target\"])\n",
    "edges_df_unweighted = edges_df.applymap(int)\n",
    "edges_df_unweighted.head(10)\n",
    "# convert edges_df_unweighted to adjacency matrix\n",
    "index = list(set(edges_df_unweighted[\"source\"].values) | set(edges_df_unweighted[\"target\"].values))\n",
    "index.sort()\n",
    "adj_matrix = np.zeros((len(index), len(index)))\n",
    "for i, row in edges_df_unweighted.iterrows():\n",
    "    source = row[\"source\"]\n",
    "    target = row[\"target\"]\n",
    "    source_index = index.index(source)\n",
    "    target_index = index.index(target)\n",
    "    adj_matrix[source_index, target_index] = 1\n",
    "\n",
    "k = 5\n",
    "k_ls = int(np.ceil(2 * np.pi * k))\n",
    "herm_A = np.exp(1j * 2 * np.pi / k) * adj_matrix + np.exp(-1j * 2 * np.pi / k) * adj_matrix.T\n",
    "herm_A_ls = np.exp(1j * 2 * np.pi / k_ls) * adj_matrix + np.exp(-1j * 2 * np.pi / k_ls) * adj_matrix.T\n",
    "degrees = np.sum(np.abs(herm_A), axis=1)\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(degrees))\n",
    "D_sqrt = np.diag(np.sqrt(degrees))\n",
    "norm_L = np.eye(len(adj_matrix)) - D_inv_sqrt @ herm_A @ D_inv_sqrt\n",
    "norm_L_ls = np.eye(len(adj_matrix)) - D_inv_sqrt @ herm_A_ls @ D_inv_sqrt\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eigh(norm_L)\n",
    "idx = eigvals.argsort()\n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "\n",
    "eigvals_ls, eigvecs_ls = np.linalg.eigh(norm_L_ls)\n",
    "idx = eigvals_ls.argsort()\n",
    "eigvals_ls = eigvals_ls[idx]\n",
    "eigvecs_ls = eigvecs_ls[:, idx]\n",
    "\n",
    "# cluster using first eigenvector\n",
    "datapoints = np.column_stack((D_inv_sqrt @ eigvecs[:, 0].real, D_inv_sqrt @ eigvecs[:, 0].imag))\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(datapoints)\n",
    "partition_numbered = [np.where(kmeans.labels_ == i)[0] for i in range(k)]\n",
    "\n",
    "rayleigh_quotients_all = []\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    # construct indicator vector of clusters\n",
    "    ind_vector = np.zeros((len(adj_matrix),), dtype=np.complex128)\n",
    "\n",
    "    for i, cluster in enumerate(partition_numbered):\n",
    "        ind_vector[cluster] = np.exp(2 * np.pi * 1j * perm[i] / k)\n",
    "\n",
    "    ind_vector = D_sqrt @ ind_vector\n",
    "    ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "\n",
    "    # rotate indicator vector to align with first eigenvector\n",
    "    alpha = np.conj(ind_vector).T @ eigvecs[:, 0]\n",
    "    ind_vector = alpha * ind_vector\n",
    "    ind_vector = ind_vector / np.linalg.norm(ind_vector)\n",
    "\n",
    "    rayleigh_quotients_all.append(np.real(np.conj(ind_vector).T @ norm_L @ ind_vector))\n",
    "\n",
    "\n",
    "# set indicator vector to be the one with the minimum rayleigh quotient\n",
    "min_perm = list(itertools.permutations(range(k)))[rayleigh_quotients_all.index(min(rayleigh_quotients_all))]\n",
    "min_ind_vector = np.zeros((len(adj_matrix),), dtype=np.complex128)\n",
    "\n",
    "for i, cluster in enumerate(partition_numbered):\n",
    "    min_ind_vector[cluster] = np.exp(2 * np.pi * 1j * min_perm[i] / k)\n",
    "\n",
    "min_ind_vector = D_sqrt @ min_ind_vector\n",
    "min_ind_vector = min_ind_vector / np.linalg.norm(min_ind_vector)\n",
    "\n",
    "# compute Psi\n",
    "Psis = []\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    C = [(perm[i], perm[i + 1]) for i in range(k - 1)] + [(perm[k - 1], perm[0])]\n",
    "    Psis.append(Psi(partition_numbered, adj_matrix, degrees, C))\n",
    "\n",
    "min_perm_psi = list(itertools.permutations(range(k)))[Psis.index(min(Psis))]\n",
    "\n",
    "# rotate indicator vector to align with first eigenvector\n",
    "alpha = np.conj(min_ind_vector).T @ eigvecs[:, 0]\n",
    "min_ind_vector = alpha * min_ind_vector\n",
    "\n",
    "thetas = []\n",
    "\n",
    "for perm in itertools.permutations(range(k)):\n",
    "    C = [(perm[i], perm[i + 1]) for i in range(len(perm) - 1)]\n",
    "    C.append((perm[-1], perm[0]))\n",
    "    theta = compute_theta(partition_numbered, adj_matrix, degrees, C)\n",
    "    thetas.append(theta)\n",
    "    \n",
    "max_perm_theta = list(itertools.permutations(range(k)))[thetas.index(max(thetas))]\n",
    "print(\"Max perm theta \", max_perm_theta)\n",
    "C = [(max_perm_theta[i], max_perm_theta[i + 1]) for i in range(len(max_perm_theta) - 1)]\n",
    "theta = compute_theta(partition_numbered, adj_matrix, degrees, C)\n",
    "\n",
    "compute_ls_bounds(eigvals_ls, theta, k)\n",
    "eigvals_ls[1] / (1 - (4 / k) * theta)\n",
    "eta = eigvals_ls[1] / (1 - (4 / k) * theta)\n",
    "print(\"Theta\", theta)\n",
    "print(\"1/eta_k\", 1 / eta)\n",
    "print(\"1/(eta_k-1)\", 1 / (eta - 1))\n",
    "print(\"Psi\", min(Psis))\n",
    "print(\"rayleigh quotient\", min(rayleigh_quotients_all))\n",
    "print(\"Our bound (Rayleigh Quotient) \",(min(rayleigh_quotients_all) - eigvals[0]) / (eigvals[1] - eigvals[0]))\n",
    "print(\"Our bound (Psi) \", (4*min(Psis) - eigvals[0])/ (eigvals[1] - eigvals[0]))\n",
    "print(\"True value \", np.linalg.norm(min_ind_vector - eigvecs[:, 0]) ** 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7192e9bc4794361"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
