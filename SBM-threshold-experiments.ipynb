{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "from graph import Graph\n",
    "from helpers import get_degree_matrix, get_laplacian_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "font = {'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b18f96023d7457f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_bounds_RST(eigenvalues, rayleigh_quotients, q):\n",
    "    \"\"\"eigenvalues is an array of the eigenvalues of the matrix\n",
    "    expected_eigenvalues is an array of the eigenvalues of the expected matrix\n",
    "    q is a list of indices. If p = len(q), then we return the lower bound for A_1, A_2, ... A_p.\n",
    "    For example, if q = [2,5] then we return the lower bounds for A_1 and A_2 where A_1 corresponds to the first two rows of alpha and A_2 corresponds to the next three rows of alpha.\"\"\"\n",
    "    A_1_lower_bound =(q[0]*eigenvalues[q[0]] - np.sum(rayleigh_quotients[0:q[0]]))/(eigenvalues[q[0]] - eigenvalues[0])\n",
    "    lower_bounds = [A_1_lower_bound]\n",
    "    for i in range(1,len(q)):\n",
    "        width = q[i] - q[i-1]\n",
    "        lower_bound = (width*eigenvalues[q[i]] - np.sum(rayleigh_quotients[q[i-1]:q[i]]) - eigenvalues[q[i]]*(q[i-1] - np.sum(lower_bounds)))/(eigenvalues[q[i]] - eigenvalues[q[i-1]])\n",
    "        lower_bounds.append(lower_bound)\n",
    "    return lower_bounds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b219872c73fcf3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def k_means_indicator_vectors(eigenvectors, K):\n",
    "    assert eigenvectors.shape[1] >= K, 'Number of eigenvectors should be greater than or equal to K'\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(eigenvectors)\n",
    "    indicator_vectors = np.zeros((eigenvectors.shape[0], K))\n",
    "    for i in range(K):\n",
    "        indicator_vectors[:,i] = kmeans.labels_ == i\n",
    "    return indicator_vectors\n",
    "\n",
    "def degree_correction(vectors, D_sqrt):\n",
    "    vectors_corrected = vectors.copy()\n",
    "    for i in range(vectors.shape[1]):\n",
    "        vectors_corrected[:,i] = D_sqrt @ vectors[:,i]\n",
    "        vectors_corrected[:,i] = vectors_corrected[:,i] / np.linalg.norm(vectors_corrected[:,i])\n",
    "    return vectors_corrected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4af2ad25eccfaf4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_k_way_estimate(normalised_L, indicator_vectors, K):\n",
    "    k_way_possibilities = []\n",
    "    assert indicator_vectors.shape[1] == K, 'Indicator vectors should have K columns'\n",
    "    for i in range(K):\n",
    "        indicator = indicator_vectors[:, i]\n",
    "        val = indicator.T @ normalised_L @ indicator\n",
    "        k_way_possibilities.append(val)\n",
    "    return max(k_way_possibilities)\n",
    "\n",
    "\n",
    "def compute_rayleigh_quotients(normalised_L, indicator_vectors, K):\n",
    "    rayleigh_quotients = []\n",
    "    assert indicator_vectors.shape[1] == K, 'Indicator vectors should have K columns'\n",
    "    for i in range(K):\n",
    "        indicator = indicator_vectors[:, i]\n",
    "        val = (indicator.T @ normalised_L @ indicator) / (indicator.T @ indicator)\n",
    "        rayleigh_quotients.append(val)\n",
    "    return rayleigh_quotients\n",
    "\n",
    "\n",
    "def compute_all_bounds(G: Graph, K: int, q: list, true_clusters: list):\n",
    "    D = get_degree_matrix(G)\n",
    "    D_sqrt = np.sqrt(D)\n",
    "    normalized_L = get_laplacian_matrix(G, normalized=True)\n",
    "\n",
    "    # compute first K eigenvectors of the normalized Laplacian\n",
    "    normalized_L_eigenvalues, normalized_L_eigenvectors = np.linalg.eigh(normalized_L)\n",
    "    idx = normalized_L_eigenvalues.argsort()\n",
    "    normalized_L_eigenvalues = normalized_L_eigenvalues[idx]\n",
    "    normalized_L_eigenvectors = normalized_L_eigenvectors[:, idx]\n",
    "\n",
    "    indicator_vectors = k_means_indicator_vectors(normalized_L_eigenvectors[:, 0:K], K)\n",
    "    indicator_vectors = degree_correction(indicator_vectors, D_sqrt)\n",
    "    beta_K_by_K = indicator_vectors.T @ normalized_L_eigenvectors[:, 0:K]\n",
    "    combined_indicator_vectors = indicator_vectors @ beta_K_by_K\n",
    "    for i in range(K):\n",
    "        combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] / np.linalg.norm(\n",
    "            combined_indicator_vectors[:, i])\n",
    "        for j in range(i):\n",
    "            combined_indicator_vectors[:, i] = combined_indicator_vectors[:, i] - (\n",
    "                        combined_indicator_vectors[:, j].T @ combined_indicator_vectors[:,\n",
    "                                                             i]) * combined_indicator_vectors[:, j]\n",
    "\n",
    "    rayleigh_quotients = compute_rayleigh_quotients(normalized_L, combined_indicator_vectors, K)\n",
    "    rayleigh_quotients = np.sort(rayleigh_quotients)\n",
    "    ST_standard = K * max(rayleigh_quotients) / normalized_L_eigenvalues[K]\n",
    "\n",
    "    # create indicator vectors from true clusters\n",
    "    true_indicator_vectors = np.zeros((len(G.vertices), K))\n",
    "    for i in range(K):\n",
    "        true_indicator_vectors[true_clusters[i], i] = 1\n",
    "    true_indicator_vectors = degree_correction(true_indicator_vectors, D_sqrt)\n",
    "    alpha = true_indicator_vectors.T @ normalized_L_eigenvectors[:, 0:K]\n",
    "    true_value = K - np.sum(np.sum(alpha ** 2, axis=1), axis=0)\n",
    "\n",
    "    recursive_ST = K - np.sum(compute_bounds_RST(normalized_L_eigenvalues, rayleigh_quotients, q))\n",
    "    general_ST = K - np.sum(compute_bounds_RST(normalized_L_eigenvalues, rayleigh_quotients, [K]))\n",
    "\n",
    "    return {'Recursive ST': recursive_ST,\n",
    "            'General ST': general_ST,\n",
    "            'ST Standard': ST_standard,\n",
    "            'True Value': true_value} "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b018c7a8414fb1f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# construct a graph from the data points using a threshold\n",
    "def construct_graph(X, threshold):\n",
    "    N = X.shape[0]\n",
    "    A = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dist = np.linalg.norm(X[i] - X[j])\n",
    "                if dist < threshold:\n",
    "                    A[i, j] = 1\n",
    "    return A"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2a81819c455a16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Varying n at the Threshold\n",
    "we take an SBM with two clusters and P defined as\n",
    "$$ P = \\begin{pmatrix}\n",
    "p & q \\\\\n",
    "q & p \\\\\n",
    "\\end{pmatrix}$$\n",
    "where $p = \\frac{\\alpha\\log(N)}{N}$ and $q = \\frac{\\beta \\log(N)}{N}$\n",
    "and $\\sqrt{\\alpha} - \\sqrt{\\beta} \\geq \\sqrt{2}$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ad8deb162b4b8ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this experiment we will fix the values of $\\alpha, \\beta$ at the threshold with $\\beta = 20$."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24b0bde6750d50fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = 2\n",
    "b = 20\n",
    "a = (np.sqrt(b) + np.sqrt(K))**2\n",
    "\n",
    "def get_P(a,b,N):\n",
    "    p = a * np.log(N) / N\n",
    "    q = b * np.log(N) / N\n",
    "    P = np.array([[p,q],[q,p]])\n",
    "    return P\n",
    "\n",
    "bounds = {}\n",
    "sample_size = 10\n",
    "for n in [200,300,400,500,600,700,800,900,1000]:\n",
    "    N = K*n\n",
    "    bounds[n] = 0\n",
    "    P = get_P(a,b,N)\n",
    "    for _ in range(sample_size):\n",
    "        edges = []\n",
    "        for i in range(K):\n",
    "            for j in range(i,K):\n",
    "                prob_existing_edge = P[i,j]\n",
    "                if i == j:\n",
    "                    for u in range(n):\n",
    "                        for v in range(u+1,n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "                                \n",
    "                else:\n",
    "                    for u in range(n):\n",
    "                        for v in range(n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "        \n",
    "        true_clusters = [list(range(i*n, (i+1)*n)) for i in range(K)]                        \n",
    "        G = Graph(vertices = list(range(n * K)), edges = edges)\n",
    "        bounds[n] = bounds[n] + pd.Series(compute_all_bounds(G, K, [1,2], true_clusters = true_clusters))\n",
    "    bounds[n] = bounds[n] / sample_size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b16378f40e6240"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Corollary 5', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "df.to_csv(\"Data/ThresholdVaryingNBeta20.csv\")\n",
    "df = pd.read_csv(\"Data/ThresholdVaryingNBeta20.csv\").set_index([\"Unnamed: 0\"])\n",
    "# df = df.drop(columns = ['General ST'])\n",
    "(df.loc[200:,:] / 2).plot(marker = 'o', xlabel = 'n', ylabel = 'Error', figsize = (10,10))\n",
    "# plt.title(r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r'$\\beta = 20, \\alpha = (\\sqrt{2} + \\sqrt{\\beta})^2$', y=1.03)\n",
    "plt.xlabel(r'Cluster size $n$')\n",
    "plt.ylabel(r'Error')\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor = (1.0,1.05))\n",
    "plt.savefig(\"Data/ThresholdVaryingNBeta20.png\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bcf9066bebcacf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Recursive ST', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "# df = df.drop(columns = ['General ST'])\n",
    "(df.loc[200:,:] / 2).plot(marker = 'o', xlabel = 'n', ylabel = 'Bound Value', figsize = (10,10), logy = True)\n",
    "# plt.title(r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r'$\\beta = 20, \\alpha = (\\sqrt{2} + \\sqrt{\\beta})^2$', y=1.03)\n",
    "plt.xlabel(r'Cluster size $n$')\n",
    "plt.ylabel(r'Error')\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor = (1.0,1.05))\n",
    "plt.savefig(\"Data/ThresholdVaryingNBeta20LogScale.png\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbf027c27066fc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_copy = pd.read_csv(\"Data/ThresholdVaryingNBeta20.csv\")\n",
    "df_copy = df_copy.set_index([\"Unnamed: 0\"])\n",
    "df_copy.columns = [\"Theorem 4\", \"Theorem 1\", \"Macgregor & Sun\", \"True Value\"]\n",
    "(df_copy.loc[200:,:] / 2).plot(marker = 'o', xlabel = 'n', ylabel = 'Bound Value', figsize = (12,10), logy=True)\n",
    "# plt.title(r'Bounds of $\\frac{1}{8}\\sum_{i=1}^8\\|f_i - \\hat{g}_i\\|^2$ for SBM with 8 clusters (with one pair)', y=1.03)\n",
    "plt.xlabel(r'Cluster size $n$', fontsize = 30)\n",
    "plt.ylabel(r'Error', fontsize = 30)\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "#plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,1.2,0.1))\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "# make legend larger\n",
    "plt.legend(fontsize=25, bbox_to_anchor = (1.0,1.05))\n",
    "plt.savefig('Data/ThresholdVaryingNBeta20LogScale.png', bbox_inches = \"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d5ab10769aecd7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = 2\n",
    "b = 1\n",
    "a = (np.sqrt(b) + np.sqrt(K)) ** 2\n",
    "\n",
    "\n",
    "def get_P(a,b,N):\n",
    "    p = a * np.log(N) / N\n",
    "    q = b * np.log(N) / N\n",
    "    P = np.array([[p,q],[q,p]])\n",
    "    return P\n",
    "\n",
    "\n",
    "bounds = {}\n",
    "sample_size = 10\n",
    "for n in [200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "    N = K*n\n",
    "    bounds[n] = 0\n",
    "    P = get_P(a, b, N)\n",
    "    for _ in range(sample_size):\n",
    "        edges = []\n",
    "        for i in range(K):\n",
    "            for j in range(i, K):\n",
    "                prob_existing_edge = P[i, j]\n",
    "                if i == j:\n",
    "                    for u in range(n):\n",
    "                        for v in range(u + 1, n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "\n",
    "                else:\n",
    "                    for u in range(n):\n",
    "                        for v in range(n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "\n",
    "        true_clusters = [list(range(i * n, (i + 1) * n)) for i in range(K)]\n",
    "        G = Graph(vertices=list(range(n * K)), edges=edges)\n",
    "        bounds[n] = bounds[n] + pd.Series(compute_all_bounds(G, K, [1, 2], true_clusters=true_clusters))\n",
    "    bounds[n] = bounds[n] / sample_size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fd0e95b7d776d21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Corollary 5', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "df.to_csv(\"Data/ThresholdVaryingNBeta1.csv\")\n",
    "#df = df.drop(columns=['General ST'])\n",
    "(df.loc[200:, :] / 2).plot(marker='o', xlabel='n', ylabel='Bound Value', figsize=(10, 10))\n",
    "# plt.title(r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r'$\\beta = 20, \\alpha = (\\sqrt{2} + \\sqrt{\\beta})^2$', y=1.03)\n",
    "plt.xlabel(r'Cluster size $n$')\n",
    "plt.ylabel(r'Error')\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "plt.xticks(np.arange(200, 1000, 100))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor=(1.0, 1.05))\n",
    "plt.savefig(\"ThresholdVaryingNBeta1.png\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d4176911ee87b66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Corollary 5', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "#df = df.drop(columns=['General ST'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8874a12d70c0bc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"Data/ThresholdVaryingNBeta1.csv\")\n",
    "df = df.set_index([\"Unnamed: 0\"])\n",
    "(df.loc[200:, :] / 2).plot(marker='o', xlabel='n', ylabel='Bound Value', figsize=(10, 10), logy=True)\n",
    "# plt.title(r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r'$\\beta = 20, \\alpha = (\\sqrt{2} + \\sqrt{\\beta})^2$', y=1.03)\n",
    "plt.xlabel(r'Cluster size $n$',fontsize=30)\n",
    "plt.ylabel(r'Error',fontsize=30)\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "plt.xticks(np.arange(200, 1000, 100), fontsize=25)\n",
    "\n",
    "plt.yticks(fontsize=25)\n",
    "# make legend larger\n",
    "plt.legend(fontsize=25, bbox_to_anchor = (1.0,1.05))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor=(1.0, 1.05))\n",
    "plt.savefig(\"Data/ThresholdVaryingNBeta1LogScale.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2d8b20531381972"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Repeating the same experiment but varying $\\beta$ with n fixed. We fix n = 500 and vary $\\beta$ from 1 to 20. We set $\\alpha = (\\sqrt{\\beta} + \\sqrt{2})^2$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56e75402649ba7f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = 2\n",
    "\n",
    "def get_P(b,N):\n",
    "    a = (np.sqrt(b) + np.sqrt(K))**2\n",
    "    p = a * np.log(N) / N\n",
    "    q = b * np.log(N) / N\n",
    "    P = np.array([[p,q],[q,p]])\n",
    "    return P\n",
    "\n",
    "bounds = {}\n",
    "sample_size = 1\n",
    "n = 500\n",
    "for b in range(5,20):\n",
    "    bounds[b] = 0\n",
    "    N = K*n\n",
    "    P = get_P(b,N)\n",
    "    for _ in range(sample_size):\n",
    "        edges = []\n",
    "        for i in range(K):\n",
    "            for j in range(i,K):\n",
    "                prob_existing_edge = P[i,j]\n",
    "                if i == j:\n",
    "                    for u in range(n):\n",
    "                        for v in range(u+1,n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "                                \n",
    "                else:\n",
    "                    for u in range(n):\n",
    "                        for v in range(n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "        \n",
    "        true_clusters = [list(range(i*n, (i+1)*n)) for i in range(K)]                        \n",
    "        G = Graph(vertices = list(range(n * K)), edges = edges)\n",
    "        bounds[b] = bounds[b] + pd.Series(compute_all_bounds(G, K, [1,2], true_clusters = true_clusters))\n",
    "    bounds[b] = bounds[b] / sample_size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c06b89d9c05705d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Corollary 5', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "# df = df.drop(columns = ['General ST'])\n",
    "df.to_csv(\"Data/ThresholdVaryingBetaAtThreshold.csv\")\n",
    "(df.loc[1:,:] / 2).plot(marker = 'o', xlabel = 'n', ylabel = 'Bound Value', figsize = (10,10))\n",
    "# plt.title(r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r' varying $\\beta$, $\\alpha = (\\sqrt{2} + \\sqrt{\\beta})^2$, cluster size $n=500$', y=1.03)\n",
    "plt.xlabel(r'$\\beta$')\n",
    "plt.ylabel(r'Error')\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "#plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor = (1.0,1.05))\n",
    "plt.savefig(\"Data/ThresholdVaryingBetaAtThreshold.png\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca7f197d3ca06f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Corollary 5', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "# df = df.drop(columns = ['General ST'])\n",
    "(df.loc[1:,:] / 2).plot(marker = 'o', xlabel = 'n', ylabel = 'Bound Value', figsize = (10,10), logy=True)\n",
    "# plt.title(r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r' varying $\\beta$, $\\alpha = (\\sqrt{2} + \\sqrt{\\beta})^2$, cluster size $n=500$', y=1.03)\n",
    "plt.xlabel(r'$\\beta$')\n",
    "plt.ylabel(r'Error')\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "#plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor = (1.0,1.05))\n",
    "plt.savefig(\"Data/ThresholdVaryingBetaAtThresholdLogScale.png\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea367cfabd8248f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_copy = pd.read_csv(\"Data/ThresholdVaryingBetaAtThreshold.csv\")\n",
    "df_copy = df_copy.set_index([\"Unnamed: 0\"])\n",
    "df_copy.columns = [\"Theorem 4\", \"Theorem 1\", \"Macgregor & Sun\", \"True Value\"]\n",
    "(df_copy.loc[1:,:] / 2).plot(marker = 'o', xlabel = 'n', ylabel = 'Bound Value', figsize = (12,10), logy=True)\n",
    "# plt.title(r'Bounds of $\\frac{1}{8}\\sum_{i=1}^8\\|f_i - \\hat{g}_i\\|^2$ for SBM with 8 clusters (with one pair)', y=1.03)\n",
    "plt.xlabel(r'$\\beta$', fontsize = 20)\n",
    "plt.ylabel(r'Error', fontsize = 20)\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "#plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,1.2,0.1))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor = (1.0,1.05))\n",
    "plt.savefig('Data/ThresholdVaryingBetaAtThresholdLogScale.png', bbox_inches = \"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4303969341fa6e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we consider fixing larger $\\alpha$ and increasing $\\beta$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "433049e461077c37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = 2\n",
    "max_b = 20\n",
    "a = 35\n",
    "\n",
    "def get_P(b, n):\n",
    "    \n",
    "    p = a * np.log(n) / n\n",
    "    q = b * np.log(n) / n\n",
    "    P = np.array([[p, q], [q, p]])\n",
    "    return P\n",
    "\n",
    "\n",
    "bounds = {}\n",
    "sample_size = 10\n",
    "n = 500\n",
    "\n",
    "for b in range(10, max_b + 10):\n",
    "    bounds[b] = 0\n",
    "    P = get_P(b, n)\n",
    "    for _ in range(sample_size):\n",
    "        edges = []\n",
    "        for i in range(K):\n",
    "            for j in range(i, K):\n",
    "                prob_existing_edge = P[i, j]\n",
    "                if i == j:\n",
    "                    for u in range(n):\n",
    "                        for v in range(u + 1, n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "\n",
    "                else:\n",
    "                    for u in range(n):\n",
    "                        for v in range(n):\n",
    "                            if np.random.rand() <= prob_existing_edge:\n",
    "                                edges.append((i * n + u, j * n + v))\n",
    "\n",
    "        true_clusters = [list(range(i * n, (i + 1) * n)) for i in range(K)]\n",
    "        G = Graph(vertices=list(range(n * K)), edges=edges)\n",
    "        bounds[b] = bounds[b] + pd.Series(compute_all_bounds(G, K, [1, 2], true_clusters=true_clusters))\n",
    "    bounds[b] = bounds[b] / sample_size\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa13714221c40ad1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    \n",
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Corollary 5', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "#df = df.drop(columns=['General ST'])\n",
    "df.to_csv(\"Data/ThresholdVaryingBetaFixedAlpha.csv\")\n",
    "(df.loc[1:, :] / 2).plot(marker='o', xlabel='n', ylabel='Bound Value', figsize=(10, 10))\n",
    "#plt.title(\n",
    " #   r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r' varying $\\beta$, $\\alpha = (\\sqrt{2} + \\sqrt{20})^2$, cluster size $n=500$',\n",
    " #   y=1.03)\n",
    "plt.xlabel(r'$\\beta$')\n",
    "plt.ylabel(r'Error')\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "#plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor=(1.0, 1.05))\n",
    "plt.savefig(\"Data/ThresholdVaryingBetaFixedAlpha.png\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3af75e7111ecbc96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bounds).T\n",
    "columns = ['Corollary 5', 'General ST', r'$\\frac{\\rho(2)}{\\lambda_3}$', 'True Value']\n",
    "df.columns = columns\n",
    "# df = df.drop(columns=['General ST'])\n",
    "df.to_csv(\"Data/ThresholdVaryingBetaFixedAlpha.csv\")\n",
    "(df.loc[1:, :] / 2).plot(marker='o', xlabel='n', ylabel='Bound Value', figsize=(10, 10), logy=True)\n",
    "#plt.title(\n",
    " #   r'Bounds of $\\frac{1}{2}\\sum_{i=1}^2\\|f_i - \\hat{g}_i\\|^2$ for SBM with 2 clusters at threshold' + '\\n' + r' varying $\\beta$, $\\alpha = (\\sqrt{2} + \\sqrt{20})^2$, cluster size $n=500$',\n",
    " #   y=1.03)\n",
    "plt.xlabel(r'$\\beta$')\n",
    "plt.ylabel(r'Error')\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "#plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,0.2,0.01))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor=(1.0, 1.05))\n",
    "plt.savefig(\"Data/ThresholdVaryingBetaFixedAlphaLogScale.png\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab1ecaa673bcb834"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_copy = pd.read_csv(\"Data/ThresholdVaryingBetaFixedAlpha.csv\")\n",
    "df_copy = df_copy.set_index([\"Unnamed: 0\"])\n",
    "df_copy.columns = [\"Theorem 4\", \"Theorem 1\", \"Macgregor & Sun\", \"True Value\"]\n",
    "(df_copy.loc[1:,:] / 2).plot(marker = 'o', xlabel = 'n', ylabel = 'Bound Value', figsize = (12,10), logy=True)\n",
    "# plt.title(r'Bounds of $\\frac{1}{8}\\sum_{i=1}^8\\|f_i - \\hat{g}_i\\|^2$ for SBM with 8 clusters (with one pair)', y=1.03)\n",
    "plt.xlabel(r'$\\beta$', fontsize = 20)\n",
    "plt.ylabel(r'Error', fontsize = 20)\n",
    "plt.grid(True)\n",
    "# add ticks\n",
    "#plt.xticks(np.arange(200,1000,100))\n",
    "#plt.yticks(np.arange(0,1.2,0.1))\n",
    "# make legend larger\n",
    "plt.legend(fontsize='large', bbox_to_anchor = (1.0,1.05))\n",
    "plt.savefig('Data/ThresholdVaryingBetaFixedAlphaLogScale.png', bbox_inches = \"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83164178242d3480"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
